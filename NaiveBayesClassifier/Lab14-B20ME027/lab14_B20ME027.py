# -*- coding: utf-8 -*-
"""Lab14_B20ME027.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IuKnK0ZdBFdwQkuI9T-pLPFFa3Wm29el
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
import seaborn as sns
from matplotlib import pyplot as plt
from sklearn.naive_bayes import GaussianNB 
from sklearn.metrics import accuracy_score

"""**1**"""

df=pd.read_csv('diabetes.csv')
X=df.drop(columns=['Outcome'])
y=df['Outcome']
columns=list(X.columns)

"""**2**"""

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,shuffle=False)

"""**3**"""

corr = df.iloc[:,:-1].corr(method="pearson")
cmap = sns.diverging_palette(250,354,80,60,center='dark',as_cmap=True)
sns.heatmap(corr, vmax=1, vmin=-.5, cmap=cmap, square=True, linewidths=.2)

sns.boxplot(df['Pregnancies'])

sns.boxplot(df['Glucose'])

sns.boxplot(df['BloodPressure'])

sns.boxplot(df['SkinThickness'])

sns.boxplot(df['Insulin'])

sns.boxplot(df['BMI'])

sns.boxplot(df['DiabetesPedigreeFunction'])

for i in columns:
     Q1_Y = df[i].quantile(0.25)
     Q3_Y = df[i].quantile(0.75)
     IQR_Y = Q3_Y-Q1_Y
     a=df[np.logical_or(df[i] < (Q1_Y- 1.5 * IQR_Y), df[i] > (Q3_Y + 1.5 * IQR_Y))]
     li=[]
     for row in a.index:
        li.append(row)
     c=df[i].mean()
     for j in li:
          df[i] = df[i].replace(df.iloc[j,columns.index(i)],c)

from sklearn.naive_bayes import MultinomialNB
mnb=MultinomialNB()
mnb.fit(X_train,y_train)
mnb.predict(X_test)
mnb.score(X_test,y_test)

sns.boxplot(df['Pregnancies'])

"""**5.**"""

from sklearn.preprocessing import KBinsDiscretizer
trans = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')
data = trans.fit_transform(X)
X=pd.DataFrame(data,columns=columns)
X.hist()

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,shuffle=False)

ar=np.array(y_train)
y_train=np.reshape(ar,(-1,1))
y_train=a
a

from sklearn.preprocessing import OneHotEncoder
ohe=OneHotEncoder(sparse=False)
a=ohe.fit_transform(y_train)

filter_0=0
for i in y_train[:,0]:
    if i==1:
        filter_0+=1
filter_0

X_train=np.array(X_train)
X_train=X_train.astype(int)
b=np.bincount(X_train[:,0])
b



class NaiveBayes():
    def prior_probability(self,X,y):
        filter_0=0
        filter_1=0
        for i in y[:,0]:
            if i==1:
                filter_0+=1
        for j in y[:,1]:
            if j==1:
                filter_1+=1
        prior_0=(filter_0)/len(y)
        prior_1=(filter_1)/len(y)
        prior_prob=[prior_0,prior_1]
        return prior_prob
    def likelihood(sef,X,y):
        n_features = X.shape[1]
    
        n_classes = 2
    
        count_matrix = []
        for i in range(n_features):
            count_feature = []
            X_feature = X[:,i]
            for j in range(n_classes):
                mask = y[:,j].astype(bool)
                counts = np.bincount(X_feature[mask])
            
                count_feature.append(counts/np.sum(counts))
            
            count_matrix.append(np.array(count_feature))
            class_count = y.sum(axis=0)
        
        return count_matrix

nb=NaiveBayes()
nb.prior_probability(X_train,a)
count_matrix=nb.likelihood(X_train,a)

def function(count_matrix,alpha,n_features):
  l=[]
  for i in range(n_features):
    num = count_matrix[i] + alpha
    l.append(num)
  return np.array(l)
def fit(count_matrix,n_features):
  for i in range(n_features):
    for j in range(2):
      count_matrix

count_matrix

"""**4**"""

for col in columns:
    ab=np.array(X_train[col]).reshape(-1,1)
    b=np.array(X_test[[col]]).reshape(-1,1)
    preds = NaiveBayes().fit(ab, y_train).predict(b)
    acu=accuracy_score(y_test,preds)
    print('accuracy score for',col,'is',acu)

from sklearn.preprocessing import KBinsDiscretizer
trans = KBinsDiscretizer(n_bins=30, encode='ordinal', strategy='uniform')
data = trans.fit_transform(X)
X=pd.DataFrame(data,columns=columns)
X.hist()

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,shuffle=False)

NB.fit = fit
NB.predict_proba = predict_proba
NB.predict = predict
y_pred = NB().fit(X_train, y_train).predict(X_test)
accuracy_score(y_test,y_pred)