# -*- coding: utf-8 -*-
"""B20ME027.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qJuVmyXUilufI-WezQgkfynUevhbQthM
"""

import keras 
from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten
from keras import Input
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from keras.datasets import cifar10
from keras.models import Sequential
from sklearn.preprocessing import OrdinalEncoder
from tensorflow import convert_to_tensor
from keras import models,layers
from sklearn.metrics import classification_report,confusion_matrix 
from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC

"""**QUESTION 1**"""

dataset=pd.read_csv('mnist_train.csv')
df1=dataset.drop(columns=['label'])

X=np.matrix(df1)
Y=(np.matrix(dataset['label'])).T
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3)

plt.imshow(X[0].reshape(28,28))

tf=np.where((Y_train == 0)|(Y_train==1))
X_train,Y_trainn=X_train[tf[0],:],Y_train[tf]
Y_train=np.transpose(Y_trainn)
tf_test=np.where((Y_test == 0)|(Y_test==1))
X_test,Y_test=X_test[tf_test[0],:],Y_test[tf_test]
Y_test=np.transpose(Y_test)

"""Autoencoder model q1"""

Size_input=784
size_hidden_l1=616
size_hidden_l2=524
size_hidden_l3=480
middle_layer_size=420
#encoding
input_img=keras.Input(shape=(Size_input))
encoder_l1=Dense(size_hidden_l1,activation='relu')(input_img)
encoder_l2=Dense(size_hidden_l2,activation='relu')(encoder_l1)
encoder_l3=Dense(size_hidden_l3,activation='relu')(encoder_l2)
mid_layer=Dense(middle_layer_size,activation='relu')(encoder_l3)
##decoding
decoder_l2=Dense(size_hidden_l3,activation='relu')(mid_layer)
decoder_l1=Dense(size_hidden_l2,activation='relu')(decoder_l2)
decoder_l0=Dense(size_hidden_l1,activation='relu')(decoder_l1)
reconstructed=Dense(Size_input,activation='relu')(decoder_l0)
##final model
model_autoencoder = keras.Model(input_img,reconstructed)
model_autoencoder.compile(optimizer='adamax',loss='mse')
model_autoencoder.fit(X_train,X_train,epochs=6)

model_autoencoder.summary()

my_putput=model_autoencoder.predict(X_test)
plt.imshow(my_putput[0].reshape(28,28))

plt.imshow(X_test[0].reshape(28,28))

plt.imshow(my_putput[3].reshape(28,28))

plt.imshow(X_test[3].reshape(28,28))

Size_input=784
size_hidden_l1=616
size_hidden_l2=524
size_hidden_l3=480
middle_layer_size=320
#encoding
input_img_1=keras.Input(shape=(Size_input))
encoder=Sequential()
encoder.add(Dense(size_hidden_l1,activation='relu'))
encoder.add(Dense(size_hidden_l2,activation='relu'))
encoder.add(Dense(size_hidden_l3,activation='relu'))
encoder.add(Dense(middle_layer_size,activation='relu'))

#encoder_model
encoded_x_train = np.array(encoder(X_train))
encoded_x_test=np.array(encoder(X_test))

svm=LinearSVC()
svm.fit(encoded_x_train,Y_train)
y_svm_pred=svm.predict(encoded_x_test)
svm.score(encoded_x_test,Y_test)

"""**Question 2**"""

model = Sequential()
model.add(Input(shape=(200,200,3)))
model.add(Conv2D(filters=28, kernel_size=(5, 5), activation='relu'))
model.add(MaxPooling2D(pool_size=(14,14)))
model.add(Conv2D(32, kernel_size=(4, 4), activation='relu'))
model.add(Flatten())
model.add(Dense(5, activation='softmax'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

model.summary()

"""**Question3**"""

(x_train,y_train),(x_test,y_test)=cifar10.load_data()
x_train=x_train/255
x_test=x_test/255

ordinal_enc=OrdinalEncoder()
ordinal_enc.fit(y_train)
y_train=ordinal_enc.transform(y_train)
y_test=ordinal_enc.fit_transform(y_test)

y_train=y_train.reshape((-1,))
y_test=y_test.reshape((-1,))

conv = Sequential()
conv.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))
conv.add(MaxPooling2D((2, 2)))
conv.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))    
conv.add(MaxPooling2D((2, 2)))
conv.add(Flatten())
conv.add(Dense(64, activation='relu'))
conv.add(Dense(10, activation='softmax'))
conv.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])
conv.summary()

conv.fit(x_train,y_train,epochs=2)

pred=conv.predict(x_test)
y_pred=[np.argmax(i) for i in pred]

confusion_matrix(y_test,y_pred)

classification_report(y_test,y_pred)